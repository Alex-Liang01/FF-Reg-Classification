---
title: "Student Data"
author: "Alex Liang"
date: "03/12/2021"
output: html_document
---

```{r}
library(tidyverse)
library(leaps)
library(corrplot)
library(car)
library(MASS)
library(randomForest)
library(caret)
library(gbm)
```

#Setting seed to create reproducable results
```{r}
set.seed(23)
```

#Cleaning the data
```{r}
ff=read.csv("forestfires.csv")
ff=ff%>%drop_na()
ff$area=log10(ff$area+1)
ff$month=as.numeric(as.factor(ff$month))
ff$day=as.numeric(as.factor(ff$day))
head(ff)
```
```{r}
w=cor(ff)
corrplot(w,method="color",order="hclust",type="upper")
```

#Now evaluating different datasets performance
```{r}
get.folds = function(n, K) {
n.fold = ceiling(n / K) 
fold.ids.raw = rep(1:K, times = n.fold)
fold.ids = fold.ids.raw[1:n]
folds.rand = fold.ids[sample.int(n)]
return(folds.rand)
}

K=10; N = nrow(ff)
folds = get.folds(N,K)

my_rmse = array(0,dim=c(4,5))
rownames(my_rmse) = c("linear_mod","best_subset","rf","gbm")

for(i in 1:5){#for k folds
  
  train_set = ff[folds!=i,]
  test_set = ff[folds==i,]
  test_set_validation=test_set$area 
  
  linear_reg = lm(area~.,train_set)
  linear_preds = predict.lm(linear_reg,test_set)
  my_rmse["linear_mod",i] = mean((test_set_validation-linear_preds)^2)
  
  
  best_sub=step.model=stepAIC(linear_reg,direction="both",trace=FALSE)
  best_preds=predict.lm(best_sub,test_set)
  my_rmse["best_subset",i]=mean((test_set_validation-best_preds)^2)
  
  random_f=randomForest(area~.,data=train_set,importance=TRUE,ntree=500)
  rf_preds=predict(random_f,test_set)
  my_rmse["rf",i]=mean((test_set_validation-rf_preds)^2)
  
  gbm=gbm(area~.,distribution = "gaussian",data=train_set)
  gbm_preds=predict.gbm(gbm,test_set)
  my_rmse["gbm",i]=mean((test_set_validation-gbm_preds)^2)
}
my_rmse
```


```{r}
for(i in 1:nrow(my_rmse)){
  print(mean(my_rmse[i,]))
}
```

```{r}
index = createDataPartition(ff$month,times=1,p=0.7,list=FALSE)
train_set1 = ff[index,]
test_set1 = ff[-index,]
test_set_validation1=test_set1$area
```


```{r}
rfGrid <-  expand.grid(mtry = c(2,3,4,5,6,7,8,9,10,11))

rfControl <- trainControl(## 10-fold CV 
                          method = "cv",
                          number = 10)

rf_Fit <- train(area ~ ., data = train_set1, 
                method = "rf", 
                n.trees=500)
rf_Fit
```

```{r}

```


```{r}
for(j in 1:5){
  best_rf=randomForest(area~.,data=train_set1,importance=TRUE,ntree=500,mtry=2)
  best_rf_preds=predict(best_rf,test_set1)
  best_rf_rmse=mean((test_set_validation1-best_rf_preds)^2)
  print(best_rf_rmse)
  
}
```

```{r}
gbmGrid=expand.grid(n.trees=c(300,400,500,600,800,1000),
                     interaction.depth=c(1,2,3),
                     shrinkage=c(0.001,0.01,0.05,0.25),
                     n.minobsinnode=c(10))
gbmControl <- trainControl(## 10-fold CV
                           method = "cv",
                           number = 10)
gbm_Fit <- train(area ~ ., data = train_set1, 
                method = "gbm", verbose=FALSE
                )
gbm_Fit
```


```{r}
best_gbm=gbm(area~.,distribution = "gaussian",data=train_set1,n.trees=50,interaction.depth=1,n.minobsinnode=10,shrinkage=0.1)
best_gbm_preds=predict.gbm(best_gbm,test_set1)
best_gbm_rmse=mean((test_set_validation1-best_gbm_preds)^2)
best_gbm_rmse
```



